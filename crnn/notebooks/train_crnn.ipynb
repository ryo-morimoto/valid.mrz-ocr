{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRZ CRNN Training\n",
    "\n",
    "MRZ (Machine Readable Zone) 用の軽量 CRNN モデルを学習する。\n",
    "\n",
    "## 概要\n",
    "- **アーキテクチャ**: CNN + BiLSTM + CTC\n",
    "- **入力**: 32x280 グレースケール画像\n",
    "- **出力**: 44文字の MRZ テキスト\n",
    "- **目標**: CER < 1%, モデルサイズ < 5MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. セットアップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 確認\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なライブラリは Colab に事前インストール済み\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import random\n",
    "import time\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 合成 MRZ データ生成\n",
    "\n",
    "PIL を使って MRZ 行画像を合成生成する。\n",
    "OCR-B フォントの代わりにモノスペースフォントを使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import string\n",
    "\n",
    "# MRZ で使用する文字セット\n",
    "MRZ_CHARS = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789<\"\n",
    "\n",
    "def generate_random_mrz_line() -> str:\n",
    "    \"\"\"\n",
    "    ランダムな MRZ 行（44文字）を生成\n",
    "    \n",
    "    実際の MRZ フォーマットに近いパターンを生成:\n",
    "    - Line 1: P<COUNTRY_CODE + NAME + FILLER\n",
    "    - Line 2: PASSPORT_NO + CHECK + NATIONALITY + DOB + CHECK + SEX + EXPIRY + CHECK + OPTIONAL + CHECK\n",
    "    \"\"\"\n",
    "    # ランダムに Line 1 か Line 2 形式を選択\n",
    "    if random.random() < 0.5:\n",
    "        # Line 1 形式: P<XXX + 名前 + <フィラー\n",
    "        doc_type = random.choice([\"P\", \"I\", \"A\", \"C\"])\n",
    "        country = \"\".join(random.choices(string.ascii_uppercase, k=3))\n",
    "        name_len = random.randint(20, 35)\n",
    "        name = \"\".join(random.choices(string.ascii_uppercase + \"<\", k=name_len))\n",
    "        line = f\"{doc_type}<{country}{name}\"\n",
    "        # 44文字にパディング\n",
    "        line = line[:44].ljust(44, \"<\")\n",
    "    else:\n",
    "        # Line 2 形式: 数字とチェックディジット\n",
    "        passport_no = \"\".join(random.choices(string.ascii_uppercase + string.digits, k=9))\n",
    "        check1 = random.choice(string.digits)\n",
    "        nationality = \"\".join(random.choices(string.ascii_uppercase, k=3))\n",
    "        dob = \"\".join(random.choices(string.digits, k=6))\n",
    "        check2 = random.choice(string.digits)\n",
    "        sex = random.choice([\"M\", \"F\", \"<\"])\n",
    "        expiry = \"\".join(random.choices(string.digits, k=6))\n",
    "        check3 = random.choice(string.digits)\n",
    "        optional = \"\".join(random.choices(string.ascii_uppercase + string.digits + \"<\", k=14))\n",
    "        check4 = random.choice(string.digits)\n",
    "        line = f\"{passport_no}{check1}{nationality}{dob}{check2}{sex}{expiry}{check3}{optional}{check4}\"\n",
    "        line = line[:44]\n",
    "    \n",
    "    return line\n",
    "\n",
    "\n",
    "def render_mrz_image(\n",
    "    text: str,\n",
    "    height: int = 32,\n",
    "    font_size: int = 24,\n",
    "    add_noise: bool = True\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    MRZ テキストを画像にレンダリング\n",
    "    \n",
    "    Args:\n",
    "        text: 44文字の MRZ テキスト\n",
    "        height: 出力画像の高さ\n",
    "        font_size: フォントサイズ\n",
    "        add_noise: ノイズを追加するか\n",
    "    \n",
    "    Returns:\n",
    "        グレースケール画像 (H, W)\n",
    "    \"\"\"\n",
    "    # モノスペースフォントを使用（Colab 環境）\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf\", font_size)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "    \n",
    "    # テキストサイズを計算\n",
    "    dummy_img = Image.new(\"L\", (1, 1))\n",
    "    dummy_draw = ImageDraw.Draw(dummy_img)\n",
    "    bbox = dummy_draw.textbbox((0, 0), text, font=font)\n",
    "    text_width = bbox[2] - bbox[0]\n",
    "    text_height = bbox[3] - bbox[1]\n",
    "    \n",
    "    # 画像を作成（白背景）\n",
    "    padding = 4\n",
    "    img_width = text_width + padding * 2\n",
    "    img = Image.new(\"L\", (img_width, height), color=255)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    # テキストを描画（黒文字）\n",
    "    y_offset = (height - text_height) // 2\n",
    "    draw.text((padding, y_offset), text, font=font, fill=0)\n",
    "    \n",
    "    # NumPy 配列に変換\n",
    "    img_array = np.array(img)\n",
    "    \n",
    "    # ノイズ追加\n",
    "    if add_noise and random.random() < 0.5:\n",
    "        noise = np.random.normal(0, 5, img_array.shape)\n",
    "        img_array = np.clip(img_array + noise, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    return img_array\n",
    "\n",
    "\n",
    "# テスト\n",
    "sample_text = generate_random_mrz_line()\n",
    "sample_img = render_mrz_image(sample_text)\n",
    "print(f\"Sample MRZ: {sample_text}\")\n",
    "print(f\"Image shape: {sample_img.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# サンプル画像を表示\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 4))\n",
    "for i, ax in enumerate(axes):\n",
    "    text = generate_random_mrz_line()\n",
    "    img = render_mrz_image(text)\n",
    "    ax.imshow(img, cmap=\"gray\")\n",
    "    ax.set_title(text, fontsize=8)\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 文字セット定義\n",
    "CHARS = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789<\"\n",
    "CHAR_TO_IDX = {c: i for i, c in enumerate(CHARS)}\n",
    "IDX_TO_CHAR = {i: c for i, c in enumerate(CHARS)}\n",
    "NUM_CLASSES = len(CHARS) + 1  # +1 for CTC blank\n",
    "\n",
    "print(f\"文字数: {len(CHARS)}\")\n",
    "print(f\"クラス数 (blank含む): {NUM_CLASSES}\")\n",
    "\n",
    "\n",
    "def encode_text(text: str) -> list:\n",
    "    \"\"\"テキストを数値インデックスに変換\"\"\"\n",
    "    return [CHAR_TO_IDX[c] for c in text if c in CHAR_TO_IDX]\n",
    "\n",
    "\n",
    "def decode_output(indices: list) -> str:\n",
    "    \"\"\"\n",
    "    CTC 出力をテキストにデコード\n",
    "    連続する同一インデックスと blank を除去\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    prev_idx = -1\n",
    "    for idx in indices:\n",
    "        if idx == len(CHARS):  # blank\n",
    "            prev_idx = idx\n",
    "            continue\n",
    "        if idx != prev_idx and idx < len(CHARS):\n",
    "            result.append(IDX_TO_CHAR[idx])\n",
    "        prev_idx = idx\n",
    "    return \"\".join(result)\n",
    "\n",
    "\n",
    "class SyntheticMRZDataset(Dataset):\n",
    "    \"\"\"\n",
    "    合成 MRZ データセット\n",
    "    \n",
    "    オンラインでランダムに MRZ 画像を生成する。\n",
    "    epoch ごとに異なるデータが生成される。\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_samples: int, max_width: int = 280):\n",
    "        self.num_samples = num_samples\n",
    "        self.max_width = max_width\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # ランダムな MRZ を生成\n",
    "        text = generate_random_mrz_line()\n",
    "        image = render_mrz_image(text, add_noise=True)\n",
    "        \n",
    "        # 正規化 (0-1)\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "        \n",
    "        # パディング（幅を max_width に統一）\n",
    "        h, w = image.shape\n",
    "        if w < self.max_width:\n",
    "            pad_w = self.max_width - w\n",
    "            image = np.pad(image, ((0, 0), (0, pad_w)), constant_values=1.0)\n",
    "        elif w > self.max_width:\n",
    "            image = image[:, :self.max_width]\n",
    "        \n",
    "        # テンソルに変換 (1, H, W)\n",
    "        image_tensor = torch.from_numpy(image).unsqueeze(0)\n",
    "        label = encode_text(text)\n",
    "        \n",
    "        return {\n",
    "            \"image\": image_tensor,\n",
    "            \"label\": torch.tensor(label, dtype=torch.long),\n",
    "            \"label_length\": len(label),\n",
    "            \"text\": text\n",
    "        }\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"バッチをまとめる（CTC Loss 用）\"\"\"\n",
    "    images = torch.stack([item[\"image\"] for item in batch])\n",
    "    labels = torch.cat([item[\"label\"] for item in batch])\n",
    "    label_lengths = torch.tensor([item[\"label_length\"] for item in batch])\n",
    "    texts = [item[\"text\"] for item in batch]\n",
    "    return {\n",
    "        \"images\": images,\n",
    "        \"labels\": labels,\n",
    "        \"label_lengths\": label_lengths,\n",
    "        \"texts\": texts\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. CRNN モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    CRNN (Convolutional Recurrent Neural Network) for MRZ OCR\n",
    "    \n",
    "    アーキテクチャ:\n",
    "    - CNN Backbone: 特徴抽出（高さを1に圧縮）\n",
    "    - BiLSTM: シーケンスモデリング\n",
    "    - Linear: 文字分類（37クラス + CTC blank）\n",
    "    \n",
    "    入力: (B, 1, 32, W) - グレースケール画像\n",
    "    出力: (T, B, 38) - 各タイムステップの文字確率\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes: int = 38, hidden_size: int = 128):\n",
    "        super().__init__()\n",
    "        \n",
    "        # CNN Backbone\n",
    "        self.cnn = nn.Sequential(\n",
    "            # Block 1: 32 -> 16\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            # Block 2: 16 -> 8\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            # Block 3: 8 -> 4\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 1)),\n",
    "            \n",
    "            # Block 4: 4 -> 2\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 1)),\n",
    "            \n",
    "            # Block 5: 2 -> 1\n",
    "            nn.Conv2d(256, 256, kernel_size=(2, 1)),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # BiLSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=256,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=2,\n",
    "            bidirectional=True,\n",
    "            batch_first=False,\n",
    "            dropout=0.1\n",
    "        )\n",
    "        \n",
    "        # 出力層\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # CNN 特徴抽出: (B, 1, 32, W) -> (B, 256, 1, W')\n",
    "        features = self.cnn(x)\n",
    "        \n",
    "        # 形状変換: (B, C, 1, W') -> (W', B, C)\n",
    "        b, c, h, w = features.shape\n",
    "        features = features.squeeze(2)\n",
    "        features = features.permute(2, 0, 1)\n",
    "        \n",
    "        # BiLSTM: (T, B, 256) -> (T, B, hidden*2)\n",
    "        lstm_out, _ = self.lstm(features)\n",
    "        \n",
    "        # 出力層: (T, B, hidden*2) -> (T, B, num_classes)\n",
    "        output = self.fc(lstm_out)\n",
    "        output = torch.log_softmax(output, dim=2)\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "def get_model_info(model):\n",
    "    \"\"\"モデル情報を取得\"\"\"\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    param_size = sum(p.numel() * p.element_size() for p in model.parameters())\n",
    "    buffer_size = sum(b.numel() * b.element_size() for b in model.buffers())\n",
    "    size_mb = (param_size + buffer_size) / 1024 / 1024\n",
    "    return {\"total_params\": total_params, \"size_mb\": size_mb}\n",
    "\n",
    "\n",
    "# モデル作成とテスト\n",
    "model = CRNN(num_classes=NUM_CLASSES)\n",
    "info = get_model_info(model)\n",
    "print(f\"パラメータ数: {info['total_params']:,}\")\n",
    "print(f\"モデルサイズ: {info['size_mb']:.2f} MB\")\n",
    "\n",
    "# 推論テスト\n",
    "x = torch.randn(1, 1, 32, 280)\n",
    "output = model(x)\n",
    "print(f\"入力: {x.shape} -> 出力: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from torch.optim import AdamW\nfrom torch.optim.lr_scheduler import OneCycleLR\n\n# ハイパーパラメータ\nBATCH_SIZE = 64\nEPOCHS = 100  # 30 → 100 に増加\nLR = 1e-3\nTRAIN_SAMPLES = 10000\nVAL_SAMPLES = 1000\nMAX_WIDTH = 280\n\n# デバイス\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Device: {device}\")\n\n# データセット\ntrain_dataset = SyntheticMRZDataset(TRAIN_SAMPLES, MAX_WIDTH)\nval_dataset = SyntheticMRZDataset(VAL_SAMPLES, MAX_WIDTH)\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    collate_fn=collate_fn,\n    num_workers=2\n)\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    collate_fn=collate_fn,\n    num_workers=2\n)\n\nprint(f\"Train batches: {len(train_loader)}\")\nprint(f\"Val batches: {len(val_loader)}\")\n\n# モデル・損失関数・オプティマイザ\nmodel = CRNN(num_classes=NUM_CLASSES).to(device)\ncriterion = nn.CTCLoss(blank=NUM_CLASSES - 1, zero_infinity=True)\noptimizer = AdamW(model.parameters(), lr=LR)\n\n# OneCycleLR: Warmup → 高学習率 → 低学習率\n# 中盤で高い学習率により局所解を脱出しやすい\nscheduler = OneCycleLR(\n    optimizer,\n    max_lr=LR * 10,           # 最大学習率 1e-2\n    epochs=EPOCHS,\n    steps_per_epoch=len(train_loader),\n    pct_start=0.1,            # 最初の10%で warmup\n    anneal_strategy='cos'     # cosine annealing\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def train_epoch(model, dataloader, criterion, optimizer, scheduler, device):\n    \"\"\"\n    1エポック分の学習\n    \n    OneCycleLR はバッチごとに学習率を更新するため、\n    scheduler.step() をバッチループ内で呼び出す。\n    \"\"\"\n    model.train()\n    total_loss = 0.0\n    \n    for batch in dataloader:\n        images = batch[\"images\"].to(device)\n        labels = batch[\"labels\"].to(device)\n        label_lengths = batch[\"label_lengths\"]\n        \n        outputs = model(images)  # (T, B, C)\n        T, B, C = outputs.shape\n        input_lengths = torch.full((B,), T, dtype=torch.long)\n        \n        loss = criterion(outputs, labels, input_lengths, label_lengths)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n        optimizer.step()\n        scheduler.step()  # OneCycleLR: バッチごとに更新\n        \n        total_loss += loss.item()\n    \n    return total_loss / len(dataloader)\n\n\ndef validate(model, dataloader, device):\n    \"\"\"検証\"\"\"\n    model.training = False  # set to inference mode\n    total_chars = 0\n    total_errors = 0\n    correct = 0\n    total = 0\n    samples = []\n    \n    with torch.no_grad():\n        for batch in dataloader:\n            images = batch[\"images\"].to(device)\n            texts = batch[\"texts\"]\n            \n            outputs = model(images)\n            \n            for i, text in enumerate(texts):\n                probs = outputs[:, i, :]\n                pred_indices = probs.argmax(dim=1).cpu().tolist()\n                pred_text = decode_output(pred_indices)\n                \n                # CER 計算\n                errors = sum(1 for a, b in zip(text, pred_text) if a != b)\n                errors += abs(len(text) - len(pred_text))\n                total_chars += len(text)\n                total_errors += errors\n                \n                if text == pred_text:\n                    correct += 1\n                total += 1\n                \n                if len(samples) < 5:\n                    samples.append({\"gt\": text, \"pred\": pred_text, \"match\": text == pred_text})\n    \n    model.training = True  # restore training mode\n    \n    cer = (total_errors / total_chars) * 100 if total_chars > 0 else 0\n    accuracy = (correct / total) * 100 if total > 0 else 0\n    \n    return {\"cer\": cer, \"accuracy\": accuracy, \"samples\": samples}"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 学習ループ\nprint(\"=\" * 60)\nprint(\"学習開始\")\nprint(\"=\" * 60)\n\nbest_cer = float(\"inf\")\nhistory = {\"train_loss\": [], \"val_cer\": [], \"val_acc\": [], \"lr\": []}\n\nstart_time = time.time()\n\nfor epoch in range(1, EPOCHS + 1):\n    epoch_start = time.time()\n    \n    # 現在の学習率を記録\n    current_lr = optimizer.param_groups[0]['lr']\n    history[\"lr\"].append(current_lr)\n    \n    # 学習（scheduler も渡す）\n    train_loss = train_epoch(model, train_loader, criterion, optimizer, scheduler, device)\n    \n    # 検証\n    val_result = validate(model, val_loader, device)\n    \n    epoch_time = time.time() - epoch_start\n    \n    # 履歴保存\n    history[\"train_loss\"].append(train_loss)\n    history[\"val_cer\"].append(val_result[\"cer\"])\n    history[\"val_acc\"].append(val_result[\"accuracy\"])\n    \n    # ログ（10エポックごと、または最初の10エポック）\n    if epoch <= 10 or epoch % 10 == 0:\n        print(f\"Epoch {epoch:3d}/{EPOCHS} | \"\n              f\"Loss: {train_loss:.4f} | \"\n              f\"CER: {val_result['cer']:.2f}% | \"\n              f\"Acc: {val_result['accuracy']:.1f}% | \"\n              f\"LR: {current_lr:.2e} | \"\n              f\"Time: {epoch_time:.1f}s\")\n    \n    # ベストモデル保存\n    if val_result[\"cer\"] < best_cer:\n        best_cer = val_result[\"cer\"]\n        torch.save({\n            \"epoch\": epoch,\n            \"model_state_dict\": model.state_dict(),\n            \"cer\": best_cer,\n            \"accuracy\": val_result[\"accuracy\"]\n        }, \"best_model.pth\")\n        if epoch <= 10 or epoch % 10 == 0:\n            print(f\"  -> Best model saved (CER: {best_cer:.2f}%)\")\n    \n    # サンプル表示（20エポックごと）\n    if epoch % 20 == 0:\n        print(\"\\n  サンプル予測:\")\n        for s in val_result[\"samples\"][:3]:\n            mark = \"OK\" if s[\"match\"] else \"NG\"\n            print(f\"    GT:   {s['gt']}\")\n            print(f\"    Pred: {s['pred']} [{mark}]\")\n        print()\n\ntotal_time = time.time() - start_time\nprint(\"\\n\" + \"=\" * 60)\nprint(\"学習完了\")\nprint(\"=\" * 60)\nprint(f\"総学習時間: {total_time:.1f}秒 ({total_time/60:.1f}分)\")\nprint(f\"ベスト CER: {best_cer:.2f}%\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 学習曲線をプロット\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\naxes[0, 0].plot(history[\"train_loss\"])\naxes[0, 0].set_title(\"Training Loss\")\naxes[0, 0].set_xlabel(\"Epoch\")\naxes[0, 0].set_ylabel(\"Loss\")\naxes[0, 0].grid(True, alpha=0.3)\n\naxes[0, 1].plot(history[\"val_cer\"])\naxes[0, 1].set_title(\"Validation CER (%)\")\naxes[0, 1].set_xlabel(\"Epoch\")\naxes[0, 1].set_ylabel(\"CER (%)\")\naxes[0, 1].axhline(y=1.0, color='r', linestyle='--', label='Target: 1%')\naxes[0, 1].legend()\naxes[0, 1].grid(True, alpha=0.3)\n\naxes[1, 0].plot(history[\"val_acc\"])\naxes[1, 0].set_title(\"Validation Accuracy (%)\")\naxes[1, 0].set_xlabel(\"Epoch\")\naxes[1, 0].set_ylabel(\"Accuracy (%)\")\naxes[1, 0].grid(True, alpha=0.3)\n\naxes[1, 1].plot(history[\"lr\"])\naxes[1, 1].set_title(\"Learning Rate (OneCycleLR)\")\naxes[1, 1].set_xlabel(\"Epoch\")\naxes[1, 1].set_ylabel(\"LR\")\naxes[1, 1].set_yscale('log')\naxes[1, 1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# 最終結果サマリー\nprint(\"\\n\" + \"=\" * 60)\nprint(\"最終結果サマリー\")\nprint(\"=\" * 60)\nprint(f\"最終 CER: {history['val_cer'][-1]:.2f}%\")\nprint(f\"最小 CER: {min(history['val_cer']):.2f}% (Epoch {history['val_cer'].index(min(history['val_cer'])) + 1})\")\nprint(f\"最終 Accuracy: {history['val_acc'][-1]:.1f}%\")\nprint(f\"目標達成: {'✅ CER < 1%' if min(history['val_cer']) < 1.0 else '❌ CER >= 1%'}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ONNX エクスポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ベストモデルをロード\n",
    "checkpoint = torch.load(\"best_model.pth\")\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model.training = False  # set to inference mode\n",
    "\n",
    "print(f\"Loaded model from epoch {checkpoint['epoch']}\")\n",
    "print(f\"CER: {checkpoint['cer']:.2f}%, Accuracy: {checkpoint['accuracy']:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ONNX エクスポート（dynamo=False で旧エクスポーター使用）\n# PyTorch 2.9+ の dynamo エクスポーターに BatchNorm 関連のバグがあるため\nmodel_cpu = model.cpu()\nmodel_cpu.training = False\ndummy_input = torch.randn(1, 1, 32, 280)\n\ntorch.onnx.export(\n    model_cpu,\n    dummy_input,\n    \"mrz_crnn.onnx\",\n    input_names=[\"image\"],\n    output_names=[\"output\"],\n    dynamic_axes={\n        \"image\": {0: \"batch\", 3: \"width\"},\n        \"output\": {0: \"seq_len\", 1: \"batch\"}\n    },\n    opset_version=17,\n    dynamo=False  # 旧エクスポーター使用（BatchNorm バグ回避）\n)\n\nimport os\nonnx_size = os.path.getsize(\"mrz_crnn.onnx\") / 1024 / 1024\nprint(f\"ONNX モデルサイズ: {onnx_size:.2f} MB\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 依存ライブラリをインストール（Colab 環境）\n!pip install onnxscript onnxruntime -q\n\n# ONNX モデルの検証\nimport onnxruntime as ort\n\nsession = ort.InferenceSession(\"mrz_crnn.onnx\")\n\n# テスト推論\ntest_input = np.random.randn(1, 1, 32, 280).astype(np.float32)\noutputs = session.run(None, {\"image\": test_input})\n\nprint(f\"ONNX 出力形状: {outputs[0].shape}\")\nprint(\"ONNX モデル検証: OK\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Google Drive に保存（オプション）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Drive をマウント\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "# モデルを保存\n",
    "import shutil\n",
    "save_dir = \"/content/drive/MyDrive/mrz_ocr\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "shutil.copy(\"best_model.pth\", f\"{save_dir}/best_model.pth\")\n",
    "shutil.copy(\"mrz_crnn.onnx\", f\"{save_dir}/mrz_crnn.onnx\")\n",
    "\n",
    "print(f\"モデルを保存しました: {save_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まとめ\n",
    "\n",
    "- **学習データ**: 合成 MRZ 画像 10,000枚\n",
    "- **検証データ**: 合成 MRZ 画像 1,000枚\n",
    "- **モデルサイズ**: ~3 MB\n",
    "- **目標精度**: CER < 1%\n",
    "\n",
    "次のステップ:\n",
    "1. `mrz_crnn.onnx` をダウンロード\n",
    "2. WASM 変換 (`onnxruntime-web`)\n",
    "3. ブラウザでの推論テスト"
   ]
  }
 ]
}